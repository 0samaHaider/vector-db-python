{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91018760-840e-4c85-969e-c88158c8f7b1",
   "metadata": {},
   "source": [
    "### Load Pre-trained Sentence Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "64ffca60-0484-4a07-87c1-91bc4e327a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a7bd1a263ef44d2a12dd04796923794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded successfully\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "print(\"Loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83643a41-3a14-4d7a-b056-1a7a86c0eca2",
   "metadata": {},
   "source": [
    "### Test Encoding of Sample Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f484c9bf-499a-46a8-86b3-9208d1aa8346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "846c0f3df4674667bbdd38282915a95f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding length: 384\n",
      "Sample of embedding: [ 0.05771338  0.12840357 -0.05404996  0.00614077 -0.08776704  0.08671194\n",
      "  0.07675532  0.0499517   0.03868663 -0.01710961]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load a pre-trained model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Test encoding\n",
    "text = \"Turning Text into Numbers\"\n",
    "embedding = model.encode(text)\n",
    "\n",
    "print(\"Embedding length:\", len(embedding))\n",
    "print(\"Sample of embedding:\", embedding[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c88c52f-d47f-4f86-8049-06b9919572e1",
   "metadata": {},
   "source": [
    "### Initialize ChromaDB Client and Create a Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f67c3e0-c617-4fd0-8630-acca89c9d202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "# Initialize the ChromaDB client\n",
    "client = chromadb.Client()\n",
    "\n",
    "# Create a collection (similar to an SQL table)\n",
    "collection = client.create_collection(name=\"my_kb_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e24a0b-3228-4a81-b4ad-7bdfadaf52a2",
   "metadata": {},
   "source": [
    "### Add Documents to ChromaDB Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "224c79f0-08e5-4b61-b144-077ba0c69796",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    \"Machine learning focuses on data.\",\n",
    "    \"Docker containerizes apps.\"\n",
    "]\n",
    "\n",
    "# Encode the documents into vectors\n",
    "embeddings = model.encode(docs)\n",
    "\n",
    "# Add the documents to the collection with IDs\n",
    "collection.add(\n",
    "    documents=docs,\n",
    "    embeddings=embeddings,\n",
    "    ids=[\"id1\", \"id2\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd80a1ab-4b04-460a-9a8b-2c9ebaa852a8",
   "metadata": {},
   "source": [
    "### Query ChromaDB with Multiple Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "923f9afd-6324-4d32-979c-0e5aeb9dcbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: How do computers learn from experience?\n",
      "Closest Document: Machine learning focuses on data.\n",
      "Document ID: id1\n",
      "Distance (similarity score): 1.2167723178863525\n",
      "==================================================\n",
      "Query: What is Docker?\n",
      "Closest Document: Docker containerizes apps.\n",
      "Document ID: id2\n",
      "Distance (similarity score): 0.6844878196716309\n",
      "==================================================\n",
      "Query: Explain machine learning algorithms.\n",
      "Closest Document: Machine learning focuses on data.\n",
      "Document ID: id1\n",
      "Distance (similarity score): 0.618829071521759\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# List of queries\n",
    "queries = [\n",
    "    \"How do computers learn from experience?\",\n",
    "    \"What is Docker?\",\n",
    "    \"Explain machine learning algorithms.\"\n",
    "]\n",
    "\n",
    "# Initialize a loop to query each question\n",
    "for query in queries:\n",
    "    # Convert the query into a vector\n",
    "    query_vector = model.encode(query)\n",
    "\n",
    "    # Perform the query to get results based on semantic similarity\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_vector],\n",
    "        n_results=1\n",
    "    )\n",
    "\n",
    "    # Print the results for each query\n",
    "    print(f\"Query: {query}\")\n",
    "    print(\"Closest Document:\", results['documents'][0][0])  # First document (index 0) from the first result (index 0)\n",
    "    print(\"Document ID:\", results['ids'][0][0])  # First ID (index 0) from the first result (index 0)\n",
    "    print(\"Distance (similarity score):\", results['distances'][0][0])  # First distance (index 0)\n",
    "    print(\"=\"*50)  # Separator between results of different queries"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
